[34m[1mwandb[0m: Detected [openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|                                                                                                                                                                                                                                                                                                                                               | 0/1250 [00:00<?, ?it/s]/root/miniconda3/envs/r1v/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Invalidate trace cache @ step 0 and module 1746: cache has only 0 modules
> /root/R1-V/src/r1-v/src/open_r1/grpo.py(88)accuracy_reward()
-> if student_answer == ground_truth:
'33'
